{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.308863초 걸렸습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import timeit\n",
    " \n",
    "start_time = timeit.default_timer() # 시작 시간 체크\n",
    " \n",
    "\n",
    "min_dataV = 0\n",
    "max_dataV = [0,0,0]\n",
    "\n",
    "#19년 20년 월별 데이터 생성\n",
    "data2019 = {}\n",
    "data2020 = {}\n",
    "\n",
    "def csv_to_dataFrame(year,dataY):\n",
    "    global min_dataV,max_dataV\n",
    "    year = str(year)\n",
    "    \n",
    "    for indx,csvF in enumerate(os.listdir('./seoul_subway_data/{}'.format(year))):\n",
    "        #19년도 데이터 안에 이미 데이터가 있으면 넘어가고 없으면 기본값으로 추가\n",
    "        if not 'data' + csvF[-10:-4] in dataY.keys():\n",
    "            dataY.setdefault('data' + csvF[-10:-4])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = pd.read_csv('./seoul_subway_data/' + year + '/' + csvF,encoding = 'UTF-8',index_col=False)\n",
    "        except Exception as e:\n",
    "            data = pd.read_csv('./seoul_subway_data/' + year + '/' + csvF,encoding = 'EUC-KR',index_col=False)\n",
    "        dataY['data' + csvF[-10:-4]] = data\n",
    "        \n",
    "    #데이터에서 불필요한 데이터 조정\n",
    "    for dataYM in dataY.keys():\n",
    "        if '역ID' in dataY[dataYM].columns:\n",
    "            dataY[dataYM].drop('등록일자',axis=1,inplace = True)\n",
    "            dataY[dataYM].rename(columns = {'하차총승객수' : '등록일자'},inplace = True)\n",
    "            dataY[dataYM].rename(columns = {'승차총승객수' : '하차총승객수'},inplace = True)\n",
    "            dataY[dataYM].rename(columns = {'역명' : '승차총승객수'},inplace = True)\n",
    "            dataY[dataYM].rename(columns = {'역ID' : '역명'},inplace = True)\n",
    "            \n",
    "        dataY[dataYM]['유동인구수'] = dataY[dataYM]['승차총승객수'] + dataY[dataYM]['하차총승객수']\n",
    "\n",
    "#지도를 어떻게 표현할지에 대해 필요있을 수 있는 코드\n",
    "#(모든 월별 지도의 최대 레전드 값을 고정을 시켜놓으면 전체적으로 볼때는 알아보기 쉬우나 특정 몇몇 지역들이 지나치게 흐려짐)\n",
    "#(월별로 지도의 최대 레전드 값을 다르게 하면 색은 눈에 띄게 표현 가능하나 전체적인 지도를 볼 때는 계속해서 레전드의 최댓값을 확인할 필요가 잇음)\n",
    "#         if max_dataV[0] < dataF[dataY]['승차총승객수'].max():\n",
    "#             max_dataV[0] = dataF[dataY]['승차총승객수'].max()\n",
    "        \n",
    "#         if max_dataV[1] < dataF[dataY]['하차총승객수'].max():\n",
    "#             max_dataV[1] = dataF[dataY]['하차총승객수'].max()\n",
    "            \n",
    "#         if max_dataV[2] < dataF[dataY]['유동인구수'].max():\n",
    "#             max_dataV[2] = dataF[dataY]['유동인구수'].max()           \n",
    "            \n",
    "        #후우....... 데이터 최적화\n",
    "        #중복되는 역명(환승선들) 합쳐서 그 역의 호선 갯수만큼 나누기\n",
    "        #사용일자/승차/하차/유동인구수 까지만 남기고 \n",
    "        a = dataY[dataYM].groupby('사용일자')\n",
    "        t_df = pd.DataFrame()\n",
    "        tmp = {}\n",
    "        for i,t in a:\n",
    "            try:\n",
    "                t = t.reset_index()\n",
    "                b_c = t.groupby('역명').count()[['승차총승객수','하차총승객수','유동인구수']]\n",
    "                b = t.groupby('역명').sum()[['승차총승객수','하차총승객수','유동인구수']]\n",
    "                k = b.divide(b_c).rename_axis('역명').reset_index()        \n",
    "                k['사용일자'] = t['사용일자']\n",
    "                tmp[i] = k\n",
    "                tmp[i] = pd.DataFrame(tmp[i])\n",
    "                \n",
    "                du_tmp = tmp[i]['역명']\n",
    "\n",
    "                #중복확인(혹시라도 역명이 동일한게 있는지 확인) / 사실 불필요한 코드\n",
    "#                 for j,x in enumerate(du_tmp.duplicated()):\n",
    "#                     try:\n",
    "#                         if x == True:\n",
    "#                             raise Exception(du_tmp[j])\n",
    "#                     except Exception as e:\n",
    "#                         print(e)\n",
    "#                         raise Exception()\n",
    "#                         break           \n",
    "            except Exception as e: \n",
    "                break\n",
    "            t_df = pd.concat([t_df,tmp[i]],axis = 0,ignore_index = True)\n",
    "\n",
    "        dataY[dataYM] = t_df \n",
    "\n",
    "csv_to_dataFrame(2019,data2019)\n",
    "csv_to_dataFrame(2020,data2020)\n",
    "\n",
    "terminate_time = timeit.default_timer() # 종료 시간 체크  \n",
    " \n",
    "print(\"%f초 걸렸습니다.\" % (terminate_time - start_time)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>크롤링으로 구 csv 만들기</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# import time\n",
    "# import os, csv\n",
    "\n",
    "# option = webdriver.ChromeOptions()\n",
    "# option.add_argument('headless')\n",
    "\n",
    "# # os.path.abspath('chromedriver')\n",
    "\n",
    "# driver = webdriver.Chrome(os.path.abspath('chromedriver'),options=option)\n",
    "# driver.get('https://gits.gg.go.kr/gtdb/web/trafficDb/railRoad/TransitSWPass.do')\n",
    "\n",
    "# time.sleep(3)\n",
    "\n",
    "# def setRadio():\n",
    "#     driver.find_element_by_xpath('//*[@id=\"radio1\"]').click()\n",
    "\n",
    "# def setSelect1(sel1):\n",
    "#     driver.find_element_by_xpath(\"//select[@name='select1']/option[text()='%s']\" %sel1).click()\n",
    "    \n",
    "# def setSelect2(sel2):\n",
    "#     driver.find_element_by_xpath(\"//select[@name='select2']/option[text()='%s']\" %sel2).click()\n",
    "\n",
    "# #soup로 고정된 html 값에서 radio1 버튼 찾아와서 클릭하기\n",
    "# setRadio()\n",
    "\n",
    "# #rad 버튼 클릭후 동적으로 변경된 웹페이지에서 select1아이디 값 가져오기\n",
    "# select1 = driver.find_element_by_id('select1')\n",
    "# t_sel1 = select1.text.split('\\n')\n",
    "# sel1 = []\n",
    "# for i,t in enumerate(t_sel1):\n",
    "#     if not t.strip() == '':\n",
    "#         sel1.append(t.strip())\n",
    "\n",
    "# #시 - 역명 넣을 csv파일 생상(기존에 있는건 삭제)\n",
    "# if os.path.exists('./seoul_subway_data/구_역명.csv'):\n",
    "#     os.remove('./seoul_subway_data/구_역명.csv')\n",
    "\n",
    "#encoding 설정 안해주면 mac은 되는데 window는 안될 때 있음 (조심)\n",
    "# with open('./seoul_subway_data/구_역명.csv','w',encoding = 'utf-8') as csvFile:\n",
    "#     writer = csv.DictWriter(csvFile,fieldnames=['구','역명'])    \n",
    "#     writer.writeheader()\n",
    "    \n",
    "# #sel1 값을 넣은 후 sel2값 넣고 검색 후 list값들을 가져온 다음 데이터 정리\n",
    "# for i in sel1:\n",
    "#     setSelect1(i)\n",
    "    \n",
    "#     sel2 = driver.find_element_by_id('select2')\n",
    "#     t_sel2 = sel2.text.split('\\n')\n",
    "#     for a in range(len(t_sel2)):\n",
    "#         t_sel2[a] = t_sel2[a].strip()\n",
    "#         #전체 선택 혹은 비어있는 경우는 넘어가기 (행정 구역만 필요하니까)\n",
    "#         if '전체선택' == t_sel2[a] or '' == t_sel2[a]:\n",
    "#             continue\n",
    "        \n",
    "#         setSelect2(t_sel2[a])\n",
    "#         driver.find_element_by_xpath('//*[@id = \"search\"]').click()\n",
    "#         li_loc = (driver.find_element_by_id('selList')).text.split('\\n')\n",
    "\n",
    "#         for i in li_loc:\n",
    "#             #가져온 list값은 매봉(1호선) 이런식으로 돼있으므로 ()를 기준으로 역이름과 호선명 나눠주기\n",
    "#             st_idx = i.find('(') + 1\n",
    "#             f_idx = i.find(')')\n",
    "#             t_sel2[a] = t_sel2[a].replace('_','')\n",
    "#             #csv파일에 바로 넣기\n",
    "#             with open('./seoul_subway_data/구_역명.csv','a',encoding = 'utf-8') as csvFile:\n",
    "#                 writer = csv.DictWriter(csvFile,fieldnames=['구','역명'])\n",
    "#                 writer.writerow({'구':t_sel2[a],'역명':i[:st_idx-1]})\n",
    "                \n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>데이터 정리 최종</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_sta_name = pd.read_csv('./seoul_subway_data/구_역명.csv',encoding='utf-8')\n",
    "\n",
    "def insert_gu(dataY):\n",
    "    global min_dataV,max_dataV\n",
    "    newData_min = {'사용일자':'', '역명':'', '승차총승객수':min_dataV, '하차총승객수':min_dataV, '유동인구수':min_dataV}\n",
    "    newData_max = {'사용일자':'', '역명':'', '승차총승객수':max_dataV[0], '하차총승객수':max_dataV[1], '유동인구수':max_dataV[2]}\n",
    "    #데이터에 구 추가\n",
    "    for dataYM in dataY.keys():\n",
    "        if not '구' in dataY[dataYM].columns:    \n",
    "            dataY[dataYM] = pd.merge(dataY[dataYM],gu_sta_name,on='역명',how = 'inner')\n",
    "\n",
    "            if True in dataY[dataYM].duplicated():\n",
    "                dataY[dataYM] = dataY[dataYM].drop_duplicates()\n",
    "                dataY[dataYM].reset_index(inplace=True,drop = True)\n",
    "\n",
    "        dataY[dataYM] = dataY[dataYM].sort_values(['사용일자','역명'],ascending = True).reset_index(drop = True)             \n",
    "        dataY[dataYM] = dataY[dataYM].append(newData_min,ignore_index=True)\n",
    "#         dataF[dataY] = dataF[dataY].append(newData_max,ignore_index=True)\n",
    "    \n",
    "insert_gu(data2019)\n",
    "insert_gu(data2020)\n",
    "\n",
    "DATA = {}\n",
    "if not 'data2019' in DATA.keys():\n",
    "    DATA['data2019'] = data2019\n",
    "if not 'data2020' in DATA.keys():\n",
    "    DATA['data2020'] = data2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>그냥 바로 해버리면 전국에 칠해지니까 서울지역으로 json 범위 축소 </h1><br><p>근데 왜 한번에 안되고 여러번에 거쳐야 되는지는 모르겠음...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json 처리 전 지역 수 :  250\n",
      "json 처리 후 지역 수 :  25\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import folium\n",
    "import webbrowser\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "geo_path = './map/skorea-municipalities-2018-geo.json'\n",
    "geo_str = json.load(open(geo_path, encoding='utf-8'))\n",
    "\n",
    "#json 데이터 안다듬어주면 전국단위로 난리남\n",
    "print('json 처리 전 지역 수 : ',len(geo_str['features']))\n",
    "min_len_geoStr = False\n",
    "k = [-1,-2]\n",
    "#서울 지역 코드 값 = 1로 시작\n",
    "#왜인지는 모르겠는데 한번에 처리가 안되서 이전 카운트 개수하고 현재 카운트 개수에 차이가 없을 때 break\n",
    "while min_len_geoStr == False:\n",
    "    if k[0] == k[1]:\n",
    "        min_len_geoStr = True\n",
    "    k[0] = len(geo_str['features'])\n",
    "    for i,t in enumerate(geo_str['features']):\n",
    "        if not t['properties']['code'][0] == '1':\n",
    "            del geo_str['features'][i]\n",
    "    k[1] = len(geo_str['features'])        \n",
    "\n",
    "print('json 처리 후 지역 수 : ',len(geo_str['features']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>지하철 클래스 생성</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json 처리 전 지역 수 :  250\n",
      "json 처리 후 지역 수 :  25\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import folium\n",
    "import webbrowser\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "geo_path = './map/skorea-municipalities-2018-geo.json'\n",
    "geo_str = json.load(open(geo_path, encoding='utf-8'))\n",
    "\n",
    "#json 데이터 안다듬어주면 전국단위로 난리남\n",
    "print('json 처리 전 지역 수 : ',len(geo_str['features']))\n",
    "min_len_geoStr = False\n",
    "k = [-1,-2]\n",
    "#서울 지역 코드 값 = 1로 시작\n",
    "#왜인지는 모르겠는데 한번에 처리가 안되서 이전 카운트 개수하고 현재 카운트 개수에 차이가 없을 때 break\n",
    "while min_len_geoStr == False:\n",
    "    if k[0] == k[1]:\n",
    "        min_len_geoStr = True\n",
    "    k[0] = len(geo_str['features'])\n",
    "    for i,t in enumerate(geo_str['features']):\n",
    "        if not t['properties']['code'][0] == '1':\n",
    "            del geo_str['features'][i]\n",
    "    k[1] = len(geo_str['features'])        \n",
    "\n",
    "print('json 처리 후 지역 수 : ',len(geo_str['features']))\n",
    "\n",
    "class subwayData:\n",
    "    global geo_str,DATA\n",
    "    \n",
    "    \"\"\"\n",
    "     --------------------\n",
    "    |    Map Function    |\n",
    "     --------------------\n",
    "    \"\"\" \n",
    "\n",
    "    def __init__(self,dataY,ym):      \n",
    "        #map 설정\n",
    "        self.map=folium.Map(location=[37.5502, 126.982], zoom_start=11, min_zoom=11,\n",
    "                    tiles='stamentoner')\n",
    "        \n",
    "        #font 설정\n",
    "        plt.rcParams['font.family'] = 'Apple Gothic'        \n",
    "        \n",
    "        self.dataY      = dataY\n",
    "        self.ym         = ym\n",
    "        self.dataYM     = 'data' + ym\n",
    "        #st_date는 있는데 end_date 가 없거나 반대면 예외처리 해줘야함 (나중에)\n",
    "        try:\n",
    "            self.dataY[self.dataYM]\n",
    "        except:\n",
    "            print('No data')\n",
    "            return False\n",
    "        \n",
    "        self.DrawGuMap()\n",
    "\n",
    "    #지하철로 구 유동인구 파악\n",
    "    def DrawGuMap(self):\n",
    "        #맵 그려주기\n",
    "        folium.Choropleth(\n",
    "            geo_data=geo_str,\n",
    "            data=self.dataY[self.dataYM], \n",
    "            columns=['구','유동인구수'], \n",
    "            key_on='feature.properties.name',\n",
    "            fill_color='PuRd',\n",
    "            legend_name='구별 지하철 유동인구 수'\n",
    "        ).add_to(self.map)\n",
    "        self.SaveMap()\n",
    "    \n",
    "    #지하철 역별 유동인구 파악\n",
    "    def DrawSubMap(self):\n",
    "        #맵 그려주기\n",
    "        folium.Choropleth(\n",
    "            geo_data=geo_str,\n",
    "            data=self.dataY[self.dataYM], \n",
    "            columns=['역명','유동인구수'], \n",
    "            key_on='feature.properties.name',\n",
    "            fill_color='PuRd',\n",
    "            legend_name='구별 지하철 유동인구 수'\n",
    "        ).add_to(self.map)\n",
    "        self.SaveMap()\n",
    "    \n",
    "    #그린 맵 파일 확인 후 저장 (나중에 html파일을 웹에 올려야 되서 따로 저장이 필요하긴함)\n",
    "    def SaveMap(self):\n",
    "        #쥬피터에서 보여주면 한글 깨져서 동일 경로 map 디렉토리에 해당 맵을 만들어줌\n",
    "        if os.path.exists('./map'):\n",
    "            if os.path.exists('./map/{}.html'.format(self.ym)):\n",
    "                os.remove('./map/{}.html'.format(self.ym))\n",
    "        else:\n",
    "            os.makedirs('./map')\n",
    "        self.map.save('./map/{}.html'.format(self.ym))    \n",
    "        \n",
    "    #파일 삭제\n",
    "    def DelMap(self):\n",
    "        if os.path.exists('./map/{}.html'.format(self.ym)):\n",
    "            os.remove('./map/{}.html'.format(self.ym))        \n",
    "\n",
    "    #파일 열기 \n",
    "    def OpenMap(self):\n",
    "        try:\n",
    "            if os.path.exists('./map/{}.html'.format(self.ym)):\n",
    "                BASE_DIR = os.path.dirname(os.path.abspath('map/{}.html'.format(self.ym)))\n",
    "                webbrowser.open('file:' + os.path.join(BASE_DIR,'{}.html'.format(self.ym)))\n",
    "                #파일 삭제전에 잠시 텀을 줘서 저장한게 보이게끔 함\n",
    "                #나중에 파일 삭제 관련해서 다시 다뤄야할 때를 대비 (이 코드 안에서 삭제를 없애야 될 수도 있음 / 그래야 html에서 가져올수 있으니까)\n",
    "                time.sleep(5)\n",
    "                self.DelMap()\n",
    "            else:\n",
    "                raise Exception(self.ym + ' file is not exist')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "        \n",
    "    \"\"\"\n",
    "     ----------------------\n",
    "    |    Graph Function    |\n",
    "     ----------------------\n",
    "    \"\"\"        \n",
    "        \n",
    "        \n",
    "    #graph를 하나로 묶고 subplots을 쓸지 나눠서 각각의 fig를 만들고 html에서 div를 통해서 구분을 지어줄지 결정해야 됨\n",
    "    def DrawBarGraph(self):\n",
    "        #임시로 사이즈는 대충 둠\n",
    "        print(self.dataY[self.dataYM])\n",
    "        plt.figure(figsize = (20,20))\n",
    "        plt.bar(self.dataY[self.dataYM]['역명'],self.dataY[self.dataYM])\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.titles('{} 유동인구 데이터'.format(dataYM))\n",
    "        plt.show()\n",
    "    \n",
    "    def DrawLineGraph(self):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def setSubwayData(dataY,ym):\n",
    "    mySub_data = subwayData(dataY,ym)\n",
    "    return mySub_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>클라이언트 딴에서 실행</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input date (ex:202010) : 202020\n",
      "No data\n"
     ]
    }
   ],
   "source": [
    "def setSubwayData(dataY,ym):\n",
    "    mySub_data = subwayData(dataY,ym)\n",
    "    return mySub_data\n",
    "\n",
    "#DATA = server와 연동해서 server의 DATA값을 가져와야 함\n",
    "if __name__ == '__main__':\n",
    "    global DATA\n",
    "    while True:\n",
    "        ym = str(input('Input date (ex:202010) : '))\n",
    "        try:\n",
    "            #DATA에 들어있는 data2019 data2020의 연도와 인풋 받은 dataYM를 비교해서 입력 형식이 틀리면 출력\n",
    "            for datayear in DATA.keys():\n",
    "                if not len(ym) == 6 or not ym[:4] in datayear:\n",
    "                    continue\n",
    "                my_subway_data = setSubwayData(DATA[datayear],ym)\n",
    "                \n",
    "            #map이 열리면 break\n",
    "            if not my_subway_data.OpenMap() == False:\n",
    "                break\n",
    "                \n",
    "            #안열리면 입력 형식에 문제있음\n",
    "            print(\"{} isn't correct year\".format(dataYM))                \n",
    "        except:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js_env",
   "language": "python",
   "name": "js_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
